# SchemaXtract - Intelligent Document Processing System

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![AWS SAM](https://img.shields.io/badge/AWS-SAM-orange)](https://aws.amazon.com/serverless/sam/)
[![React](https://img.shields.io/badge/React-18-blue)](https://reactjs.org/)
[![Vite](https://img.shields.io/badge/Vite-5-purple)](https://vitejs.dev/)
[![Python](https://img.shields.io/badge/Python-3.12-green)](https://www.python.org/)

An intelligent document processing (IDP) system powered by LayoutLMv3 for automated field extraction from invoices and documents, with interactive learning capabilities and strict GDPR compliance.

## ğŸŒŸ Features

- **AI-Powered Extraction**: LayoutLMv3 document understanding model for accurate field detection
- **GDPR Compliant**: No permanent storage of original documents - all processing in ephemeral storage
- **3-Service Architecture**:
  - AWS Lambda backend for document processing
  - Donut/LayoutLMv3 ML service for field extraction
  - React frontend for interactive annotation
- **Serverless Ready**: AWS SAM for Lambda deployment with local testing
- **Modern Frontend**: React + Vite with drag-and-drop annotations
- **Document Understanding**: Spatial+textual analysis using transformer models
- **Flexible Deployment**: Works in Codespaces, local dev, or cloud

## ğŸš€ Quick Start

### Prerequisites

- **Docker** (for SAM Local Lambda containers and ML service)
- **Node.js 18+** (for frontend)
- **Python 3.12** (pre-installed in devcontainer)
- **8GB RAM** recommended for ML model

### Option 1: Using GitHub Codespaces (â­ Recommended)

1. Click the **"Code"** button on GitHub
2. Select **"Codespaces"** tab
3. Click **"Create codespace on main"**
4. Wait for automatic setup (5-8 minutes)
   - Container builds with all dependencies
   - Python packages installed
   - Frontend dependencies installed
5. Once ready, run services using VS Code Tasks:
   - Press `Ctrl+Shift+P` (or `Cmd+Shift+P`)
   - Type **"Tasks: Run Task"**
   - Select **"Start All Services"**
6. Open the forwarded port 3000 in your browser

**First run downloads:**

- Lambda runtime images (~900MB)
- PyTorch + LayoutLMv3 model (~3.6GB)
- These are cached for subsequent runs

### Option 2: Local Development with Dev Containers

1. **Clone the repository**

   ```bash
   git clone https://github.com/Dwys97/schemaxtract.git
   cd schemaxtract
   ```

2. **Open in VS Code**

   ```bash
   code .
   ```

3. **Reopen in Container**

   - Press `Ctrl+Shift+P`
   - Select **"Dev Containers: Reopen in Container"**
   - Wait for container build and setup

4. **Start services** (same as Codespaces above)

5. **Install and run frontend** (in new terminal)

   ```bash
   cd frontend
   npm install
   npm run dev
   ```

6. **Access the application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:3001/process-document

## ğŸ“ Project Structure

```
schemaxtract/
â”œâ”€â”€ .devcontainer/          # Codespace/devcontainer configuration
â”‚   â”œâ”€â”€ devcontainer.json
â”‚   â””â”€â”€ setup.sh
â”œâ”€â”€ backend/                # AWS SAM Lambda backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ process_document/
â”‚   â”‚       â””â”€â”€ app.py      # Lambda handler
â”‚   â”œâ”€â”€ template.yaml       # SAM/CloudFormation template
â”‚   â””â”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ frontend/               # Vite/React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx         # Main React component
## ğŸ—ï¸ Architecture

### 3-Service Architecture

```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ React Frontend â”‚â”€â”€â”€â”€â”€â–¶â”‚ Lambda Backend â”‚â”€â”€â”€â”€â”€â–¶â”‚ Donut ML Service â”‚
â”‚ (Port 3000) â”‚ â”‚ (Port 3001) â”‚ â”‚ (Port 3002) â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ - Upload UI â”‚ â”‚ - PDFâ†’Image â”‚ â”‚ - LayoutLMv3 Model â”‚
â”‚ - Annotations â”‚ â”‚ - SAM Local â”‚ â”‚ - Field Extraction â”‚
â”‚ - Vite + React â”‚ â”‚ - API Gateway â”‚ â”‚ - PyTorch + HF â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

### Service Details

1. **Frontend (Vite + React)**
   - Document upload interface
   - Interactive bounding box annotations
   - Field review and correction
   - Modern UI with drag-and-drop

2. **Backend (AWS Lambda via SAM)**
   - PDF to image conversion (pdf2image + poppler)
   - API Gateway integration
   - Calls Donut service for field extraction
   - GDPR-compliant ephemeral processing

3. **Donut Service (Flask + LayoutLMv3)**
   - LayoutLMv3 transformer model
   - Document understanding (spatial + textual)
   - Field extraction with bounding boxes
   - Runs on CPU or GPU

## ğŸ“ Project Structure

```

schemaxtract/
â”œâ”€â”€ .devcontainer/
â”‚ â”œâ”€â”€ devcontainer.json # Dev container config (Docker-in-Docker)
â”‚ â”œâ”€â”€ Dockerfile # Python 3.12 + system dependencies
â”‚ â””â”€â”€ setup.sh # Post-create automation
â”œâ”€â”€ .vscode/
â”‚ â””â”€â”€ tasks.json # VS Code tasks for starting services
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ template.yaml # SAM/CloudFormation template
â”‚ â”œâ”€â”€ samconfig.toml # SAM local dev settings
â”‚ â”œâ”€â”€ requirements.txt # Lambda dependencies
â”‚ â””â”€â”€ src/
â”‚ â””â”€â”€ process_document/
â”‚ â”œâ”€â”€ app.py # Lambda handler
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ donut_service/
â”‚ â”œâ”€â”€ main.py # Flask server with LayoutLMv3
â”‚ â”œâ”€â”€ requirements.txt # PyTorch + Transformers
â”‚ â””â”€â”€ Dockerfile # ML service container
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ App.jsx # Main app component
â”‚ â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”‚ â”œâ”€â”€ DocumentUploader.jsx
â”‚ â”‚ â”‚ â”œâ”€â”€ DocumentViewerModal.jsx
â”‚ â”‚ â”‚ â””â”€â”€ AnnotationCanvas.jsx
â”‚ â”‚ â””â”€â”€ main.jsx
â”‚ â”œâ”€â”€ package.json
â”‚ â””â”€â”€ vite.config.js
â”œâ”€â”€ START_HERE.md # Quick start (up-to-date)
â”œâ”€â”€ DONUT_SERVICE_MIGRATION.md # Architecture details
â””â”€â”€ README.md # This file

````

## ğŸ”§ Development

### Using VS Code Tasks (Easiest)

Press `Ctrl+Shift+P` â†’ `Tasks: Run Task` â†’ Select:
- **Start All Services** - Starts all 3 services in parallel
- **Start Backend (SAM Local)** - Backend only (port 3001)
- **Start Frontend (Vite)** - Frontend only (port 3000)
- **Start Donut Service** - ML service only (port 3002)
- **Build Backend Only** - SAM build
- **Stop All Services** - Stop everything

### Manual Development

**Backend (AWS SAM Local):**
```bash
cd backend
sam build                  # Build Lambda function
sam local start-api --port 3001 --host 0.0.0.0
````

**Frontend (Vite):**

```bash
cd frontend
npm run dev -- --host 0.0.0.0
# Opens on http://localhost:3000
```

**Donut ML Service:**

```bash
cd donut_service
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python main.py
# Runs on http://localhost:3002
```

### Test the Services

**Backend:**

```bash
curl -X POST http://localhost:3001/process-document \
  -H "Content-Type: application/json" \
  -d '{"document": "dGVzdA==", "filename": "test.pdf"}'
```

**Donut Service:**

```bash
curl http://localhost:3002/health
# Should return: {"status": "healthy"}
```

**Frontend:**
Open http://localhost:3000 in browser

## ğŸ§ª Testing

### Quick Health Checks

```bash
# Check all dependencies
python3 --version  # Should be 3.12.x
node --version     # Should be v18.x
docker ps          # Should list running containers
sam --version      # Should be 1.145.x+

# Test Donut ML service
curl http://localhost:3002/health

# Test Backend
curl -X POST http://localhost:3001/process-document \
  -H "Content-Type: application/json" \
  -d '{"document": "dGVzdA==", "filename": "test.pdf"}'

# Test Frontend
curl http://localhost:3000
```

### Load Testing

First-time ML model loading takes ~30-60 seconds. Subsequent requests are fast.

See **START_HERE.md** and **DONUT_SERVICE_MIGRATION.md** for detailed information.

## ğŸ”’ GDPR Compliance

This system is designed with GDPR compliance at its core:

- âœ… **No permanent document storage** - Original documents never saved to disk
- âœ… **10GB ephemeral storage** - All processing in `/tmp/` (cleared after execution)
- âœ… **Explicit file deletion** - Files removed immediately after processing
- âœ… **Audit logging** - All file operations logged for compliance
- âœ… **Anonymized training data** - Only coordinates and text stored, decoupled from images

## ğŸš¢ Deployment

### Deploy to AWS

```bash
cd backend
sam build --use-container
sam deploy --guided
```

This will:

1. Build the Lambda container image
2. Push to Amazon ECR
3. Create Lambda function with 10GB ephemeral storage
4. Set up API Gateway
5. Configure CloudWatch Logs

### Environment Variables

Set these in the SAM template or AWS Console:

- `LOG_LEVEL`: Logging level (default: INFO)
- `PYTHONUNBUFFERED`: Set to 1 for real-time logs

## ğŸ“Š Performance

Current metrics (Phase 1 baseline):

| Metric            | Value   | Target   |
| ----------------- | ------- | -------- |
| Lambda Memory     | 2048 MB | 2048+ MB |
| Lambda Timeout    | 90s     | 90+ s    |
| Ephemeral Storage | 10 GB   | 10 GB    |
| Cold Start        | ~85ms   | <1s      |
| Warm Response     | ~42ms   | <100ms   |

## ğŸ—ºï¸ Roadmap

### Phase 1: Foundation âœ… COMPLETE

- [x] Dockerfile with Lambda runtime
- [x] SAM template with GDPR configuration
- [x] Basic Lambda handler
- [x] Frontend scaffolding
- [x] Local development setup

### Phase 2: OCR Integration ğŸš§ IN PROGRESS

- [ ] PebbleOCR integration
- [ ] OpenCV preprocessing
- [ ] PDF handling
- [ ] Real document testing

### Phase 3: LayoutML

- [ ] LayoutML model integration
- [ ] Field prediction
- [ ] Template learning endpoint
- [ ] S3 integration for training data

### Phase 4: Interactive UI

- [ ] PDF viewer component
- [ ] Annotation tools
- [ ] Field labeling interface
- [ ] Template management

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- AWS Lambda team for serverless runtime
- PebbleOCR for OCR capabilities
- LayoutML for document understanding
- React and Vite communities

## ğŸ“ Support

- ğŸ“– Documentation: See [QUICK_START.md](QUICK_START.md)
- ğŸ› Issues: [GitHub Issues](https://github.com/Dwys97/schemaxtract/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/Dwys97/schemaxtract/discussions)

## ğŸ”— Links

- [AWS SAM Documentation](https://docs.aws.amazon.com/serverless-application-model/)
- [Vite Documentation](https://vitejs.dev/)
- [React Documentation](https://reactjs.org/)
- [Docker Documentation](https://docs.docker.com/)
